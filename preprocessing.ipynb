{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the topic name here\n",
    "topic_name = 'Political'\n",
    "\n",
    "# entry folder for the data\n",
    "# should be the form of 'data_{topic_name}/'\n",
    "entry_folder = 'data_Political/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(image_url, csv_path):\n",
    "    image_name = image_url.split('/')[-1]\n",
    "    image_path = './' + csv_path[:-4] + '/' + image_name\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.DataFrame(columns=['hashtag', 'tweet_id', 'image_path', 'body_text'])\n",
    "df_csv['tweet_id'] = df_csv['tweet_id'].astype('int64')\n",
    "\n",
    "entries = os.listdir(entry_folder)\n",
    "for hashtag in entries:\n",
    "    if hashtag.startswith('.'): continue\n",
    "    list_files = glob.glob(entry_folder + hashtag + '/*.csv')\n",
    "    tweets_count = 0\n",
    "    for csv_path in list_files:\n",
    "        # print(csv_path)\n",
    "        temp_df = pd.read_csv(csv_path)\n",
    "        tweets_count += len(temp_df.index)\n",
    "        temp_df.drop(columns=['tweet_url'], inplace=True)\n",
    "        temp_df.rename({'text_data': 'body_text', 'media': 'image_path'}, axis='columns', inplace=True)\n",
    "        temp_df.insert(loc=0, column='hashtag', value=hashtag)\n",
    "        cols = temp_df.columns.tolist()\n",
    "        # before: cols = ['hashtag', 'image_path', 'body_text', 'tweet_id']\n",
    "        cols = cols[:1] + cols[-1:] + cols[1:-1]\n",
    "        temp_df = temp_df[cols]\n",
    "        temp_df['image_path'] = temp_df['image_path'].apply(get_image_path, csv_path=csv_path)\n",
    "        temp_df['tweet_id'] = temp_df['tweet_id'].astype('int64')\n",
    "        df_csv = df_csv.append(temp_df)\n",
    "    print('{:>24s}: {:>5}'.format(hashtag, tweets_count))\n",
    "print('Topic: {} - Total tweets: {:>5}'.format(topic_name, len(df_csv.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tweets with invalid image path\n",
    "df_csv['path_is_valid'] = df_csv['image_path'].apply(lambda x: 1 if os.path.isfile(x) else 0)\n",
    "df_csv = df_csv[df_csv.path_is_valid.eq(1)]\n",
    "df_csv.drop(columns=['path_is_valid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.reset_index(drop=True, inplace=True)\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out images without text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from opencv_text_detector import TextDetector\n",
    "\n",
    "tqdm.pandas()\n",
    "detector = TextDetector()\n",
    "\n",
    "# df_csv['has_text'] = df_csv['image_path'].apply(detector.detect_text)\n",
    "df_csv['has_text'] = df_csv['image_path'].progress_apply(detector.detect_text)\n",
    "\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = './csv_data/data_' + topic_name + '.csv'\n",
    "df_csv.to_csv(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out those images without text\n",
    "result_path = './csv_data/data_' + topic_name + '.csv'\n",
    "df_csv = pd.read_csv(result_path, index_col=0)\n",
    "\n",
    "df_csv_cleaned = df_csv[df_csv.has_text.eq(1)]\n",
    "df_csv_cleaned.drop(columns=['has_text'], inplace=True)\n",
    "df_csv_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "result_cleaned_path = './csv_data/data_' + topic_name + '_cleaned.csv'\n",
    "df_csv_cleaned.to_csv(result_cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the tweets in different hashtags after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cleaned_path = './csv_data/data_' + topic_name + '_cleaned.csv'\n",
    "df_csv_cleaned = pd.read_csv(result_cleaned_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the tweets in different hashtags after cleaning\n",
    "df_csv_cleaned['hashtag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out duplicate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cleaned_path = './csv_data/data_' + topic_name + '_cleaned.csv'\n",
    "cleaned_data = pd.read_csv(result_cleaned_path, index_col=0)\n",
    "imagePaths = cleaned_data['image_path'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from remove_duplicates import duplicate_detector\n",
    "no_duplicate_paths = duplicate_detector(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "cleaned_data['no_dups'] = cleaned_data['image_path'].apply(lambda x:1 if x in no_duplicate_paths else 0)\n",
    "df_csv_cleaned = cleaned_data[cleaned_data.no_dups.eq(1)]\n",
    "df_csv_cleaned.drop(columns=['no_dups'], inplace=True)\n",
    "df_csv_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_csv_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cleaned_path = './csv_data/data_' + 'AsianHate' + '_cleaned_nodups.csv'\n",
    "df_csv_cleaned.to_csv(result_cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_cleaned['hashtag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "cd1f5da85199302314bd73b2bb6f21c64cad1b4f001173fa3ddb4057b62cb3fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
